Kafka:
	распределенный последовательный лог
	отказоустойчивая
		есть независымые узлы которые выполняют одни и те же функции
		имеет много репликаций
	Базовая структура хранения в кафка: ключ-значение-таймстамп

Kafka кластер:
	это zookeper и kafka-broker в любом количестве вместе

zookeper
	это база данных которая обеспечиваем максимальную скорость чтения,
		запись не такая быстрая

нода:
	это kafka-broker

producer
	система которая порождает сообщения в кластер
	это наша система

consumer
	система которая потребляет сообщения из кластера
	это наша система
	при перебалансировке нагрузки на 1 consumer может приходиться несколько патриций
	чтение данных из партиции просходит последовательно,
		последовательность только из партиции, не общей записи на кластер

topic
	это система для логического разделения данных в кафка, логический уровень представления
	это как система объединяющая базы данных

партиция
	деление топика случайным образом на части, эти части хранят сообщения
	это как отдельная база данных
	из партиции может читать только 1 consumer, даже если есть свободные consumer
	количество партиций нужно делать примерно в 4 раза больше чем сервисов

CAP теорема
	консистентность, доступность, сетевые отказы

Партиционирвоание(шардирование)
	producer -> kafka -> consumer
		множество producer пишет в множество kafka и читает множество consumer,
			это считается патриционированием
	количество партиций задается при создание топика через скрипт(bin/kafka-topics.sh)
		--create --partitions count_partition --topic name_topic
		или через api(когда топики нужно задавать динамически)
	по умолчанию количество партиций равно 1

Репликация
	на сколько нод будут сохраняться данные патриций
	задается при создании топика(bin/kafka-topics.sh)
		--create --replication-factor count_replica --topic name_topic
		или через апи
	по умолчанию 1 реплика, рекомендуется делать минимум 3 реплики
	реплики бывают in-sync и not in-sync
		количество in-sync реплик настраевается min.insync.replicas
	проиходит по системе leader-folower,
		все пишется на лидер ноду а с нее копируется на реплики

Потеря сообщений:
	кафка меняет лидера самостоятельно и из синхронизации могут быть удалены сообщения
		что бы эту проблему решить исользуется asks параметр, возможные значения
			all(сообщение должно быть записано на все in sync реплики
				возрастает время записи из за синхронизации на все insync ноды),
			non(не важно если потеряется), one(на лидера)

Данных в кафка:
	у каждой записи(сообщения) есть:
		номер записи
		время записи
		ключ записи(опционально)
		данные записи

	множество сообщений записываются в 1 пакет(батч) и пишутся к кафку одновременно
		у батча есть параметры baseOffset, lastOffset, count, position,
			CreatedTime(совпадает с последним сообщением), size,
			messages(offset, CreatedTime, payload)
		пока не накопим батч(накапливается на продюсере) не передаем сообщение в кафку,
		условие на отправку это размер батч в килобайтах и время которое подождать пока
		записывается батч(10 млсек по умолчанию)
	использует пакетную передачу сообщений, это повышает производительность 
		и добавляет латентность
		настраевается размер в килобайтах
	хранение данных
		хранит в отдельных файлах
		данные можно не удалять или можно настроить время удаления
	для того что бы ориентироваться по данных у кафка есть оффсет(смещение)


4.1.1
настрйоки продюсера
	batch.size размер буффера (не некомендуется изменять)
	max.request.bytes макимальный размер пачки
	
	linger.ms
		таймаут на отправку, для кафки дорого открывать сокет, дешево писать на диск

	acks подтверждение пакетов репликации, null, one, all
	retries
		сколько раз клиент попробует записть в топик если кафка не ответила
		retry.backoff.ms
	max.in.flight.request.per.connection
		количество одновременно не посланых батчей которые храняться
			но может спутаться порядок
	auto.commit.enabled
		включить авто коммит
	стратегия распределения топиков
		partition.assignment.strategy
			range как то подругому 
			roundRobin поровну на всех


























